{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "70cea06b-9af4-4cde-96d0-d35e769e328f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<ipyparallel.client.client.Client at 0x7f982c525490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ipyparallel as ipp\n",
    "\n",
    "cluster = ipp.Cluster.from_file(\"/root/.ipython/profile_default/security/cluster-.json\")\n",
    "rc = cluster.connect_client_sync()\n",
    "rc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fbdef5-ec5e-4f34-ada4-844349b6a3ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 07:05:34.534091: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-11-06 07:05:34.604395: I tensorflow/core/util/util.cc:169] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2022-11-06 07:05:34.624298: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segmentation Models: using `keras` framework.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import segmentation_models as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "710a81fa-a7f0-4437-94ec-a548985a6d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT_DIR = os.path.abspath(os.getcwd())\n",
    "DATASETS_DIR = os.path.join(ROOT_DIR, \"datasets\")\n",
    "ICH_420_DATASET = os.path.join(DATASETS_DIR, \"ICH_420\")\n",
    "ICH_420_DATASET_TFRECORDS = os.path.join(ICH_420_DATASET, \"TFRecords\")\n",
    "ICH_420_DATASET_TFRECORDS_TRAIN = os.path.join(ICH_420_DATASET_TFRECORDS, \"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dc12ef5-cc17-4d6e-be0f-bb53c8e3f32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_train_test(tfrecords_pattern, test_rate=0.2, buffer_size=10000):\n",
    "    filenames = tf.io.gfile.glob(tfrecords_pattern)\n",
    "    random.shuffle(filenames)\n",
    "    split_idx = int(test_rate * len(filenames))\n",
    "    \n",
    "\n",
    "    return filenames[split_idx:], filenames[:split_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "739cec77-12d3-492d-b48a-03d92d9eefcb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 605\n",
      "Test: 151\n"
     ]
    }
   ],
   "source": [
    "train_dataset_filepaths, test_dataset_filepaths = split_train_test(os.path.join(ICH_420_DATASET_TFRECORDS_TRAIN, \"*.tfrecord\"))\n",
    "print(f\"Train: {len(train_dataset_filepaths)}\")\n",
    "print(f\"Test: {len(test_dataset_filepaths)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6463a7ab-b4e6-41a8-8bc9-bb7b2d750d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_image(image, img_type, dtype=tf.float32, bit=12):\n",
    "    image = tf.io.parse_tensor(image, out_type=np.uint16, name=img_type)\n",
    "    image = tf.expand_dims(image, axis=-1)\n",
    "    image = tf.cast(image, dtype) / (2 ** bit)\n",
    "    \n",
    "    return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "154982f2-dec6-4c14-9e0b-cf75d5585d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_tfrecord(example):\n",
    "    features_description = {\n",
    "        \"filename\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"number\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"sample\": tf.io.FixedLenFeature([], tf.int64),\n",
    "        \"image_raw\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"mask_raw\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    \n",
    "    example = tf.io.parse_single_example(example, features_description, name=\"nii\")\n",
    "    image = decode_image(example[\"image_raw\"], img_type=\"image\")\n",
    "    mask = decode_image(example[\"mask_raw\"], img_type=\"mask\")\n",
    "\n",
    "    return image, mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4a0ea51d-e3ee-4b96-90e3-3476a76c8b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(filenames):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.shuffle(2048, reshuffle_each_iteration=False)\n",
    "    dataset = dataset.map(read_tfrecord, num_parallel_calls=tf.data.AUTOTUNE)\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b69ac241-5b99-4612-ae96-e840988080cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(filenames):\n",
    "    dataset = load_dataset(filenames)\n",
    "    dataset = dataset.prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "    dataset = dataset.batch(8)\n",
    "    dataset = dataset.repeat()\n",
    "    \n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28025e52-6d71-418d-ae16-7adcf5b2f1a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = get_dataset(train_dataset_filepaths)\n",
    "test_dataset = get_dataset(test_dataset_filepaths)\n",
    "\n",
    "train, test = iter(train_dataset).next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a7c05012-146d-452d-b6dc-739409cbae5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_input = sm.get_preprocessing(\"resnet50\")\n",
    "train_dataset = preprocess_input(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5d3dfe3f-4c25-44e8-8d52-57f458808c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = sm.Unet(\"resnet50\", encoder_weights=None, input_shape=(None, None, 1))\n",
    "# tf.keras.utils.plot_model(model, show_dtype=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7bf68ba-2547-4b7e-a7f4-078a1a35e20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    'Adam',\n",
    "    loss=sm.losses.dice_loss,\n",
    "    metrics=[sm.metrics.iou_score, sm.metrics.f1_score],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "080f7390-e67f-413f-8058-b98be208adb3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-11-06 07:05:50.984599: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:390] Filling up shuffle buffer (this may take a while): 1563 of 2048\n",
      "2022-11-06 07:05:54.318851: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:415] Shuffle buffer filled.\n",
      "2022-11-06 07:05:54.838453: I tensorflow/stream_executor/cuda/cuda_dnn.cc:384] Loaded cuDNN version 8100\n",
      "2022-11-06 07:05:55.708555: I tensorflow/stream_executor/cuda/cuda_blas.cc:1614] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Type mismatch between parsed tensor (int32) and dtype (uint16)\n\t [[{{node image}}]]\n\t [[IteratorGetNext]]\n\t [[cond_1/then/_39/cond_1/cond/then/_204/cond_1/cond/remove_squeezable_dimensions/Rank_1/_118]]\n  (1) INVALID_ARGUMENT:  Type mismatch between parsed tensor (int32) and dtype (uint16)\n\t [[{{node image}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_14813]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "Cell \u001b[0;32mIn [15], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_dataset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m          \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m          \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1000\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m          \u001b[49m\u001b[43mverbose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\n\u001b[1;32m      5\u001b[0m \u001b[43m         \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mInvalidArgumentError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) INVALID_ARGUMENT:  Type mismatch between parsed tensor (int32) and dtype (uint16)\n\t [[{{node image}}]]\n\t [[IteratorGetNext]]\n\t [[cond_1/then/_39/cond_1/cond/then/_204/cond_1/cond/remove_squeezable_dimensions/Rank_1/_118]]\n  (1) INVALID_ARGUMENT:  Type mismatch between parsed tensor (int32) and dtype (uint16)\n\t [[{{node image}}]]\n\t [[IteratorGetNext]]\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_14813]"
     ]
    }
   ],
   "source": [
    "model.fit(train_dataset,\n",
    "          epochs=2,\n",
    "          steps_per_epoch=1000,\n",
    "          verbose=2\n",
    "         )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
